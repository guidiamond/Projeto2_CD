{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Autom√°tico de Sentimento\n",
    "\n",
    "Voc√™ foi contratado por uma empresa parar analisar como os clientes est√£o reagindo a um determinado produto no Twitter. A empresa deseja que voc√™ crie um programa que ir√° analisar as mensagens dispon√≠veis e classificar√° como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mere√ßam destaque, disparem um foco de aten√ß√£o da √°rea de marketing.<br /><br />\n",
    "Como aluno de Ci√™ncia dos Dados, voc√™ lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que √© largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conte√∫do.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, voc√™ precisa implementar uma vers√£o do classificador que \"aprende\" o que √© relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Ap√≥s validado, o seu prot√≥tipo poder√° tamb√©m capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informa√ß√µes do Projeto\n",
    "\n",
    "Prazo: 19/Set at√© √†s 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas ter√° uma rubrica diferenciada.<br /><br />\n",
    "Entreg√°veis via GitHub: \n",
    "* Arquivo notebook com o c√≥digo do classificador, seguindo as orienta√ß√µes abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**N√ÉO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermedi√°ria: Check 1 - APS 2\n",
    "\n",
    "At√© o dia 10/Set √†s 23:59, xlsx deve estar no Github com as seguintes evid√™ncias: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes j√° classificadas.\n",
    "\n",
    "Sugest√£o de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. N√£o se esque√ßa de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. N√£o remover emojis.<br />\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apple üçé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao iniciar nosso projeto de Ci√™ncia dos Dados, tinhamos como objetivo aplicar conceitos vistos em sala, como o Classificador Naive Bayes, Laplace Smothing, entre outros. Para isso, foi proposto que, com a ajuda do ``Python`` e algumas de suas bibliotecas, fizessemos nosso pr√≥prio classificador de sentimentos de alguma empresa, com base em tweets obtidos atrav√©s de uma API disponibilizada. Com isso escolhemos fazer um classificador de relev√¢ncia da empresa ``Apple`` ``(relevante / irrelevante)`` na ``linguagem inglesa``, por gerar muita ``ambiguidade entre a fruta e a empresa`` em si, caracterizando um problema provavelmente muito recorrente para recebimento de feedbacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√µes do Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def limpeza_de_dados(treinamento, coluna):\n",
    "    dados_limpos = []\n",
    "    for e in treinamento[coluna]:\n",
    "        limpeza = e.replace('\\n', '')\n",
    "        limpeza = str(limpeza)\n",
    "        limpeza = limpeza.replace('t.co', '')\n",
    "        limpeza = limpeza.replace('https://', '')\n",
    "        limpeza = limpeza.replace('#', '')\n",
    "        limpeza = limpeza.replace(':', '')\n",
    "        limpeza = limpeza.replace(',', '')\n",
    "        limpeza = limpeza.replace('.', '')\n",
    "        limpeza = limpeza.replace('/', '')\n",
    "        limpeza = limpeza.replace('//', '')\n",
    "        limpeza = limpeza.replace('...', '')\n",
    "        limpeza = limpeza.replace(';', '')\n",
    "        limpeza = limpeza.replace('\\'', '')\n",
    "        limpeza = limpeza.replace('rt', '')\n",
    "        limpeza = limpeza.replace('@', '')\n",
    "        limpeza = limpeza.lower()\n",
    "        limpeza = limpeza.split(' ')\n",
    "        dados_limpos.append(limpeza)\n",
    "\n",
    "    return dados_limpos\n",
    "\n",
    "def contagem_palavras(dados_limpos):\n",
    "    contagem = {}\n",
    "    for e in dados_limpos:\n",
    "        for all in e:\n",
    "            if all not in contagem:\n",
    "                contagem[all] = 1\n",
    "            else:\n",
    "                contagem[all] += 1\n",
    "    del contagem['']\n",
    "    \n",
    "    return contagem\n",
    "\n",
    "def frequencia_das_palavras(contagem):\n",
    "    probabilidade_palavra = {}\n",
    "    soma = sum(contagem.values())\n",
    "    for k in contagem:\n",
    "        probabilidade_palavra[k] = contagem[k] / soma\n",
    "\n",
    "    return probabilidade_palavra\n",
    "\n",
    "def laplace_smoothing(probabilidade_palavra, prob_total):\n",
    "    laplace_probabilidade_palavra = {}\n",
    "    for k in probabilidade_palavra:\n",
    "        laplace_probabilidade_palavra[k] = np.log( (probabilidade_palavra[k]+1) / prob_total )\n",
    "        \n",
    "    return laplace_probabilidade_palavra\n",
    "\n",
    "def calculador_probabilidade(frases_tratadas, laplace_probabilidade_positivo, laplace_probabilidade_negativo, probabilidade_positivo_total, probabilidade_negativo_total):\n",
    "    resultado = []\n",
    "    for e in frases_tratadas: #loop frase\n",
    "        conta_positivo = []\n",
    "        conta_negativo = []\n",
    "        for all in e: #loop palavras da frase\n",
    "            for k in laplace_probabilidade_positivo: #loop nas frequencias positivas\n",
    "                if all in k: #se a palavra estiver no dicionario de frequencias positivas\n",
    "                    conta_positivo.append(laplace_probabilidade_positivo[k]) #adicionar a lista conta_positivo a probabilidade da palavra k\n",
    "            for k in laplace_probabilidade_negativo:\n",
    "                if all in k:\n",
    "                    conta_negativo.append(laplace_probabilidade_negativo[k])\n",
    "        prob_positivo = np.prod(conta_positivo) * probabilidade_positivo_total\n",
    "        prob_negativo = np.prod(conta_negativo) * probabilidade_negativo_total\n",
    "        if prob_positivo > prob_negativo:\n",
    "            resultado.append(1)\n",
    "        else:\n",
    "            resultado.append(0)\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do Classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura / Limpeza / Contagem dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Leitura dos daods de treinamento\n",
    "leitura_excel_treinamento = pd.read_excel('tweets_apple.xlsx', sheet_name='Treinamento')\n",
    "\n",
    "# Divisao dos dados entre relevante e irrelevante (positivo/negativo)\n",
    "treinamento_raw_positivo = leitura_excel_treinamento[leitura_excel_treinamento.Relevancia==1]\n",
    "treinamento_raw_negativo = leitura_excel_treinamento[leitura_excel_treinamento.Relevancia==0]\n",
    "\n",
    "# Limpeza dos dados (positivo/negativo)\n",
    "limpeza_positivo = limpeza_de_dados(treinamento_raw_positivo, 'Treinamento')\n",
    "limpeza_negativo = limpeza_de_dados(treinamento_raw_negativo, 'Treinamento')\n",
    "\n",
    "# Contagem das palavras (positivo/negativo)\n",
    "contagem_positivo = contagem_palavras(limpeza_positivo)\n",
    "contagem_negativo = contagem_palavras(limpeza_negativo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplica√ß√£o de Naive Bayes e Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidades Totais (total / total positiva / total negativa)\n",
    "prob_total = len(treinamento_raw_positivo) + len(treinamento_raw_negativo)\n",
    "probabilidade_positivo_total = np.log(len(treinamento_raw_positivo) + 1 / (len(treinamento_raw_positivo) + len(treinamento_raw_negativo)))\n",
    "probabilidade_negativo_total = np.log(len(treinamento_raw_negativo) + 1 / (len(treinamento_raw_positivo) + len(treinamento_raw_negativo)))\n",
    "\n",
    "# Probabilidade de cada palavra dado (positivo / negativo)\n",
    "frequencia_palavra_positivo = frequencia_das_palavras(contagem_positivo)\n",
    "frequencia_palavra_negativo = frequencia_das_palavras(contagem_negativo)\n",
    "\n",
    "# Aplicacao de Laplace smoothing nos dados (positivo/negativo)\n",
    "laplace_probabilidade_positivo = laplace_smoothing(frequencia_palavra_positivo, prob_total)\n",
    "laplace_probabilidade_negativo = laplace_smoothing(frequencia_palavra_negativo, prob_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste do Classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza / Calculo / Classificacao dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "87\n",
      "1.2873563218390804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:35: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_prod(a, axis, dtype, out, keepdims)\n"
     ]
    }
   ],
   "source": [
    "#Leitura dos dados de teste\n",
    "leitura_excel_teste = pd.read_excel('tweets_apple.xlsx', sheet_name='Teste')\n",
    "\n",
    "#Limpeza dos dados\n",
    "teste_tratado = limpeza_de_dados(leitura_excel_teste, 'Teste')\n",
    "teste_tratado\n",
    "\n",
    "\n",
    "a=calculador_probabilidade(teste_tratado, laplace_probabilidade_positivo,laplace_probabilidade_negativo, probabilidade_positivo_total, probabilidade_negativo_total)\n",
    "leitura_excel_teste['batata'] = a\n",
    "leitura_excel_teste\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compara√ß√£o de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "87\n",
      "1.2873563218390804\n"
     ]
    }
   ],
   "source": [
    "batata = limpeza = leitura_excel_teste.batata.sum()\n",
    "rel = limpeza = leitura_excel_teste.Relevancia.sum()\n",
    "print(batata)\n",
    "print(rel)\n",
    "print(112/87)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclus√£o.<br /> \n",
    "Fa√ßa um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como s√£o tratadas as mensagens com dupla nega√ß√£o e sarcasmo.<br />\n",
    "Proponha um plano de expans√£o. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que n√£o posso alimentar minha base de Treinamento automaticamente usando o pr√≥prio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cen√°rios de uso para o classificador Naive-Bayes. Cen√°rios sem intersec√ß√£o com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indica√ß√µes concretas de como implementar (n√£o √© preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
